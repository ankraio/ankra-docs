---
title: Prometheus
description: Connect Prometheus as a metrics data source for real-time cluster insights
---

<Note>
Connect your Prometheus instance to Ankra to view metrics directly in the platform. This powers resource graphs, the AI Assistant's metrics awareness, and cluster health indicators.
</Note>

## Why Connect Prometheus?

When you connect Prometheus to Ankra:

- **Resource Metrics** - View CPU, memory, and network graphs on pods, deployments, and nodes
- **AI-Powered Analysis** - The AI Assistant can query your metrics to diagnose issues
- **Cluster Overview** - See aggregate metrics on the cluster dashboard
- **Troubleshooting** - Correlate metrics with logs and events in one place

---

## Supported Endpoints

Ankra connects to any Prometheus-compatible endpoint:

| Provider | Example Endpoint |
|----------|------------------|
| Self-hosted Prometheus | `http://prometheus.monitoring.svc.cluster.local:9090` |
| Prometheus via port-forward | `http://localhost:9090` |
| Grafana Cloud | `https://prometheus-prod-xx-xxx.grafana.net` |
| Amazon Managed Prometheus | `https://aps-workspaces.<region>.amazonaws.com/workspaces/<id>` |
| Google Cloud Managed Prometheus | `https://monitoring.googleapis.com/v1/projects/<project>` |
| Thanos Query | `http://thanos-query.monitoring.svc.cluster.local:9090` |
| Victoria Metrics | `http://victoria-metrics.monitoring.svc.cluster.local:8428` |

---

## Connecting Prometheus

<Steps>
  <Step title="Open Cluster Settings">
    Navigate to your cluster and go to **Settings** in the sidebar.
  </Step>
  <Step title="Find Metrics Data Source">
    Scroll to the **Metrics Data Source** section.
  </Step>
  <Step title="Select Prometheus">
    Choose **Prometheus** from the data source dropdown.
  </Step>
  <Step title="Enter the Endpoint">
    Enter your Prometheus endpoint URL.

    For in-cluster Prometheus, use the internal service URL:
    ```
    http://prometheus-server.monitoring.svc.cluster.local:9090
    ```
    For kube-prometheus-stack:
    ```
    http://prometheus-operated.monitoring.svc.cluster.local:9090
    ```
  </Step>
  <Step title="Add Authentication (if required)">
    If your Prometheus requires authentication, add a credential:
    - **API Token** - For bearer token authentication
    - **User Account** - For basic auth (username/password)
  </Step>
  <Step title="Test Connection">
    Click **Test Connection** to verify Ankra can reach your Prometheus instance.
  </Step>
  <Step title="Save">
    Click **Save** to store the configuration.
  </Step>
</Steps>

---

## Authentication Options

<Tabs>
  <Tab title="No Authentication">
    For Prometheus instances without authentication (common for in-cluster deployments):
    Simply enter the endpoint URL and save. No credentials needed.
  </Tab>
  <Tab title="API Token">
    For Prometheus instances using bearer token authentication:

    1. Create a credential with type **API Token**
    2. Enter your token value
    3. Select this credential in the Metrics Data Source settings

    Ankra sends the token as: `Authorization: Bearer <token>`
  </Tab>
  <Tab title="Basic Auth">
    For Prometheus instances using username/password:
    1. Create a credential with type **User Account**
    2. Enter the username and password
    3. Select this credential in the Metrics Data Source settings
  </Tab>
</Tabs>

---

## In-Cluster vs External Prometheus

### In-Cluster Prometheus

If Prometheus runs inside the same cluster:

1. Use the internal Kubernetes service URL
2. No authentication is typically needed
3. The Ankra agent forwards requests through the cluster network

**Common service URLs:**

```
# Standard Prometheus
http://prometheus-server.monitoring.svc.cluster.local:9090

# kube-prometheus-stack
http://prometheus-operated.monitoring.svc.cluster.local:9090

# Prometheus Operator
http://prometheus-k8s.monitoring.svc.cluster.local:9090
```

### External Prometheus

If Prometheus runs outside the cluster (cloud managed, separate infrastructure):

1. Use the external URL (must be reachable from your cluster)
2. Configure authentication as required by your provider
3. Ensure network connectivity and firewall rules allow access

---

## Creating Credentials

If your Prometheus requires authentication:

<Steps>
  <Step title="Go to Credentials">
    Navigate to **Credentials** in the main navigation (or use `⌘+K` → "Credentials").
  </Step>
  <Step title="Create New Credential">
    Click **Create Credential** and select:
    - **API Token** for bearer token auth
    - **User Account** for basic auth
  </Step>
  <Step title="Enter Details">
    - **Name** - A descriptive name like "prometheus-prod"
    - **Token** or **Username/Password** - Your authentication details
  </Step>
  <Step title="Save">
    The credential is now available in the Metrics Data Source dropdown.
  </Step>
</Steps>

---

## Verifying the Connection

After connecting Prometheus:

1. **Check the Settings Page** - You should see a green "Connected" status
2. **View Resource Metrics** - Go to any pod or deployment and check for metric graphs
3. **Ask the AI** - Press `⌘+J` and ask "What's the CPU usage of this pod?"

If metrics aren't showing:

- Verify the endpoint URL is correct
- Check that Prometheus has data for your cluster
- Test the connection from the settings page
- Check network connectivity between your cluster and Prometheus

---

## Troubleshooting

<AccordionGroup>
  <Accordion title="Connection Test Fails">
    1. Verify the URL is correct and includes the port
    2. For in-cluster Prometheus, ensure the service exists:
       ```bash
       kubectl get svc -n monitoring
       ```
    3. Check if Prometheus is running:
       ```bash
       kubectl get pods -n monitoring -l app=prometheus
       ```
    4. Test connectivity from within the cluster:
       ```bash
       kubectl run curl --rm -it --image=curlimages/curl -- curl http://prometheus-server.monitoring:9090/api/v1/query?query=up
       ```
  </Accordion>
  <Accordion title="Authentication Errors">
    1. Verify the credential is correctly configured
    2. For API tokens, ensure the token hasn't expired
    3. For basic auth, verify the username and password are correct
    4. Check Prometheus logs for authentication failures
  </Accordion>
  <Accordion title="Metrics Not Appearing">
    1. Prometheus may not have metrics for the resource yet (wait for scrape interval)
    2. Verify Prometheus is scraping the correct targets
    3. Check the Prometheus UI targets page for scrape errors
    4. Ensure the metric names match what Ankra expects (standard Kubernetes metrics)
  </Accordion>
  <Accordion title="Slow Queries">
    1. Large time ranges can be slow. Try narrower ranges.
    2. Consider using recording rules for frequently-queried metrics
    3. Check Prometheus resource usage (may need more CPU/memory)
  </Accordion>
</AccordionGroup>

---

## What Metrics Does Ankra Use?

Ankra queries standard Kubernetes and node metrics:

| Metric | Source | Used For |
|--------|--------|----------|
| `container_cpu_usage_seconds_total` | cAdvisor | Pod/container CPU graphs |
| `container_memory_working_set_bytes` | cAdvisor | Pod/container memory graphs |
| `node_cpu_seconds_total` | node-exporter | Node CPU usage |
| `node_memory_MemAvailable_bytes` | node-exporter | Node memory usage |
| `kube_pod_status_phase` | kube-state-metrics | Pod status indicators |
| `kube_deployment_status_replicas` | kube-state-metrics | Deployment health |

If you're using kube-prometheus-stack, all these metrics are included by default.

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Build a Monitoring Stack" icon="chart-line" href="/guides/monitoring-stack">
    Deploy Prometheus and Grafana with one Stack.
  </Card>
  <Card title="AI Assistant" icon="wand-magic-sparkles" href="/essentials/ai-assistant">
    Use the AI to query and analyze your metrics.
  </Card>
  <Card title="Kubernetes Insights" icon="magnifying-glass-chart" href="/essentials/kubernetes-insights">
    Explore built-in cluster dashboards.
  </Card>
  <Card title="Credentials" icon="key" href="/integrations/credentials">
    Manage authentication for all integrations.
  </Card>
</CardGroup>
